{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Final Project\n",
    "\n",
    "Spring 2017 - NYU CUSP\n",
    "\n",
    "Notebook reads in datetime converted CitiBike Data by month (e.g. Jan_citi.csv) from 2016 and converts gets the counts and means per month\n",
    "\n",
    "Written in Python 2.7 (Anaconda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherstreich/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/christopherstreich/anaconda2/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['compress', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import geopandas as gp\n",
    "#from geopandas import GeoDataFrame\n",
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score as rs\n",
    "from sklearn import svm, datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "np.random.seed(222)\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pd.options.display.max_columns = 120\n",
    "pd.options.display.max_rows = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for spurious entires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove spurious trip length rationale\n",
    "\n",
    "From website: A $101 security deposit hold will be placed on your card when you purchase a pass. If you incur usage\n",
    "\n",
    "fees, your card will be charged. The fee for a lost or stolen bike is $1200 (+ tax).\n",
    "\n",
    "\n",
    "## Total Loss: \n",
    "\n",
    "Annual pass = 163/year + 101 Security fee + ($ 2.50 * min) = 5616 minutes\n",
    " \n",
    "3 day Pass = 24 + 101 Security fee + ($ 2.50 * 15min) = 4031.25\n",
    "\n",
    "Day Pass = 12 + 101 Security fee + ($4 * 15min) = 4076.25\n",
    "\n",
    "Ride = 4 + 101 Security fee + ($4 * 15min) = 4106.25 \n",
    "\n",
    "So remove anything longer than 5616 minutes, the maximum time before Total Loss and keep trip long than 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def citi_agg_stat_day(label):\n",
    "    '''This function is supposed to: Further clean citi bike data, Group by day, \n",
    "    get daily count and mean and then export the files to prepare for a large merge'''\n",
    "    #Import the csv\n",
    "    getfile = \"data/\" + label + \".csv\"\n",
    "    citi_agg = pd.read_csv(getfile)\n",
    "    #Drop column\n",
    "    citi_agg.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    #change seconds to minutes\n",
    "    citi_agg['tripduration'] = citi_agg['tripduration'].apply(lambda x: x / 60)\n",
    "    #Remove spurious trips\n",
    "    citi_agg = citi_agg[(citi_agg.tripduration > 1) & (citi_agg.tripduration < 5616)]\n",
    "    #DatTime again??\n",
    "    citi_agg['starttime'] = pd.to_datetime(citi_agg['starttime'])\n",
    "    citi_agg['stoptime'] = pd.to_datetime(citi_agg['stoptime'])\n",
    "    #Count Trips per day \n",
    "    citi_agg['bike_date'] = citi_agg['starttime'].dt.date\n",
    "    citi_day_count = citi_agg.groupby(['bike_date'], as_index=False)['tripduration'].count()\n",
    "    citi_day_count.columns = ['bike_date', 'bike_trip_count']\n",
    "    \n",
    "    #take the mean of the taxi stats each day\n",
    "    citi_stat_agg = citi_agg.groupby(['bike_date'], as_index=False).mean()\n",
    "    \n",
    "    #Merge the seperate DataFrames \n",
    "    citi_df_by_day = citi_stat_agg.merge(citi_day_count, on='bike_date')\n",
    "    \n",
    "    #Get the weekday\n",
    "    citi_df_by_day['weekday'] = 0\n",
    "    for i in range(len(citi_df_by_day)):\n",
    "        citi_df_by_day['weekday'].iloc[i] = citi_df_by_day.bike_date.iloc[i].weekday()\n",
    "        \n",
    "    #Export to csv\n",
    "    output = \"data/\" + label + \"_df_by_day.csv\"\n",
    "    citi_df_by_day.to_csv(output)\n",
    "    #citi_df_byday_all\n",
    "    return citi_df_by_day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def citi_daystation_count(label):\n",
    "    '''This function is supposed to: Further clean citi bike data, do some grouping\n",
    "    and calculations and then export the files to prepare for a large merge'''\n",
    "    #Import the csv\n",
    "    getfile1 = \"data/\" + label + \".csv\"\n",
    "    citi_agg1 = pd.read_csv(getfile1)\n",
    "    #Drop column\n",
    "    citi_agg1.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    #change seconds to minutes\n",
    "    citi_agg1['tripduration'] = citi_agg1['tripduration'].apply(lambda x: x / 60)\n",
    "    #Remove spurious trips\n",
    "    citi_agg1 = citi_agg1[(citi_agg1.tripduration > 1) & (citi_agg1.tripduration < 5616)]\n",
    "    #DatTime again??\n",
    "    citi_agg1['starttime'] = pd.to_datetime(citi_agg1['starttime'])\n",
    "    citi_agg1['stoptime'] = pd.to_datetime(citi_agg1['stoptime'])\n",
    "    #citi_agg['day_number'] = label.starttime.apply(lambda x: x.hour)\n",
    "    citi_agg1['bike_date'] = citi_agg1['starttime'].dt.date\n",
    "    \n",
    "    \n",
    "    #Count Trips per day \n",
    "    citi_agg1['bike_date'] = citi_agg1['starttime'].dt.date\n",
    "    citi_day_count1 = citi_agg1.groupby(['bike_date', \"start_station id\"], as_index=False)['tripduration'].count()\n",
    "    citi_day_count1.columns = ['bike_date', \"start_station id\",'bike_trip_count']\n",
    "    return citi_day_count1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by day and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns =['bike_date', 'tripduration', 'start_station id', 'start_station_latitude', 'start_station_longitude', \\\n",
    "          'end_station_id', 'end_station_latitude','end_station_longitude', 'bikeid', 'birth_year', \\\n",
    "          'gender', 'start_hour', 'end_hour','bike_trip_count', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = [\"Jan_citi\", \"Feb_citi\", \"Mar_citi\", \"Apr_citi\", \"May_citi\", \"Jun_citi\", \"Jul_citi\", \"Aug_citi\", \\\n",
    "          \"Sep_citi\", \"Oct_citi\", \"Nov_citi\", \"Dec_citi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Empty dataframe\n",
    "citi_df_all_day = pd.read_csv(io.StringIO(None), names=columns, dtype=dict(zip(columns,[object, float, float, float, float, float, float, float, float, float, float, float, float, int, int])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherstreich/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#Create the files in bulk\n",
    "By day with count and mean\n",
    "for i in (months):\n",
    "    x = citi_agg_stat_day(str(i))\n",
    "    citi_df_all_day = citi_df_all_day.append(x, ignore_index = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "citi_df_all_day.to_csv('data/citi_df_all_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_date</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start_station id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>bike_trip_count</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bike_date, tripduration, start_station id, start_station_latitude, start_station_longitude, end_station_id, end_station_latitude, end_station_longitude, bikeid, birth_year, gender, start_hour, end_hour, bike_trip_count, weekday]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citi_df_all_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by station and time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = [\"Jan_citi\", \"Feb_citi\", \"Mar_citi\", \"Apr_citi\", \"May_citi\", \"Jun_citi\", \"Jul_citi\", \"Aug_citi\", \\\n",
    "          \"Sep_citi\", \"Oct_citi\", \"Nov_citi\", \"Dec_citi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns2 =['bike_date', 'start_station id', 'bike_trip_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station = pd.read_csv(io.StringIO(None), names=columns2, dtype=dict(zip(columns,[object, int, int])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Station count grouped by day\n",
    "for i in (months):\n",
    "    y = citi_daystation_count(str(i))\n",
    "    citi_day_by_station = citi_day_by_station.append(y, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station.to_csv('data/citi_day_by_station.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tlc_df_by_day[['bike_trip_count', 'tripduration']]\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_date</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start_station id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>bike_trip_count</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bike_date, tripduration, start_station id, start_station_latitude, start_station_longitude, end_station_id, end_station_latitude, end_station_longitude, bikeid, birth_year, gender, start_hour, end_hour, bike_trip_count, weekday]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citi_df_all_day.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyshp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-a9f0cc5c3b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyshp\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named pyshp"
     ]
    }
   ],
   "source": [
    "import pyshp as pys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "install_name_tool -id libspecial.dylib libspecial.dylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "libSystem.B.dylib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Run: Christophers-MacBook-Pro:lib christopherstreich$ otool -L /Users/christopherstreich/anaconda2/lib/libgdal.20.dylib\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Get: @rpath/libjpeg.8.dylib (compatibility version 13.0.0, current version 13.0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
