{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Final Project\n",
    "\n",
    "Spring 2017 - NYU CUSP\n",
    "\n",
    "Notebook reads in datetime converted CitiBike Data by month (e.g. Jan_citi.csv) from 2016 and converts gets the counts and means per month\n",
    "\n",
    "Written in Python 2.7 (Anaconda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geoffperrin/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "WARNING: pylab import has clobbered these variables: ['compress', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "from geopandas import GeoDataFrame\n",
    "import os\n",
    "import subprocess\n",
    "from shapely.geometry import Point\n",
    "from datetime import datetime\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score as rs\n",
    "from sklearn import svm, datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "np.random.seed(222)\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pd.options.display.max_columns = 120\n",
    "pd.options.display.max_rows = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proj_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for spurious entires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove spurious trip length rationale\n",
    "\n",
    "From website: A $101 security deposit hold will be placed on your card when you purchase a pass. If you incur usage\n",
    "\n",
    "fees, your card will be charged. The fee for a lost or stolen bike is $1200 (+ tax).\n",
    "\n",
    "\n",
    "## Total Loss: \n",
    "\n",
    "Annual pass = 163/year + 101 Security fee + ($ 2.50 * min) = 5616 minutes\n",
    " \n",
    "3 day Pass = 24 + 101 Security fee + ($ 2.50 * 15min) = 4031.25\n",
    "\n",
    "Day Pass = 12 + 101 Security fee + ($4 * 15min) = 4076.25\n",
    "\n",
    "Ride = 4 + 101 Security fee + ($4 * 15min) = 4106.25 \n",
    "\n",
    "So remove anything longer than 5616 minutes, the maximum time before Total Loss and keep trip long than 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def citi_agg_stat_day(label):\n",
    "    '''This function is supposed to: Further clean citi bike data, Group by day, \n",
    "    get daily count and mean and then export the files to prepare for a large merge'''\n",
    "    #Import the csv\n",
    "    getfile = \"data/\" + label + \".csv\"\n",
    "    citi_agg = pd.read_csv(getfile)\n",
    "    #Drop column\n",
    "    citi_agg.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    #change seconds to minutes\n",
    "    citi_agg['tripduration'] = citi_agg['tripduration'].apply(lambda x: x / 60)\n",
    "    #Remove spurious trips\n",
    "    citi_agg = citi_agg[(citi_agg.tripduration > 1) & (citi_agg.tripduration < 5616)]\n",
    "    #DatTime again??\n",
    "    citi_agg['starttime'] = pd.to_datetime(citi_agg['starttime'])\n",
    "    citi_agg['stoptime'] = pd.to_datetime(citi_agg['stoptime'])\n",
    "    #Count Trips per day \n",
    "    citi_agg['bike_date'] = citi_agg['starttime'].dt.date\n",
    "    citi_day_count = citi_agg.groupby(['bike_date'], as_index=False)['tripduration'].count()\n",
    "    citi_day_count.columns = ['bike_date', 'bike_trip_count']\n",
    "    \n",
    "    #take the mean of the taxi stats each day\n",
    "    citi_stat_agg = citi_agg.groupby(['bike_date'], as_index=False).mean()\n",
    "    \n",
    "    #Merge the seperate DataFrames \n",
    "    citi_df_by_day = citi_stat_agg.merge(citi_day_count, on='bike_date')\n",
    "    \n",
    "    #Get the weekday\n",
    "    citi_df_by_day['weekday'] = 0\n",
    "    for i in range(len(citi_df_by_day)):\n",
    "        citi_df_by_day['weekday'].iloc[i] = citi_df_by_day.bike_date.iloc[i].weekday()\n",
    "        \n",
    "    #Export to csv\n",
    "    output = \"data/\" + label + \"_df_by_day.csv\"\n",
    "    citi_df_by_day.to_csv(output)\n",
    "    #citi_df_byday_all\n",
    "    return citi_df_by_day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def citi_daystation_count(label):\n",
    "    '''This function is supposed to: Further clean citi bike data, do some grouping\n",
    "    and calculations and then export the files to prepare for a large merge'''\n",
    "    #Import the csv\n",
    "    getfile1 = \"data/\" + label + \".csv\"\n",
    "    citi_agg1 = pd.read_csv(getfile1)\n",
    "    #Drop column\n",
    "    citi_agg1.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    #change seconds to minutes\n",
    "    citi_agg1['tripduration'] = citi_agg1['tripduration'].apply(lambda x: x / 60)\n",
    "    #Remove spurious trips\n",
    "    citi_agg1 = citi_agg1[(citi_agg1.tripduration > 1) & (citi_agg1.tripduration < 5616)]\n",
    "    #DatTime again??\n",
    "    citi_agg1['starttime'] = pd.to_datetime(citi_agg1['starttime'])\n",
    "    citi_agg1['stoptime'] = pd.to_datetime(citi_agg1['stoptime'])\n",
    "    #citi_agg['day_number'] = label.starttime.apply(lambda x: x.hour)\n",
    "    citi_agg1['bike_date'] = citi_agg1['starttime'].dt.date\n",
    "    \n",
    "    \n",
    "    #Count Trips per day \n",
    "    citi_agg1['bike_date'] = citi_agg1['starttime'].dt.date\n",
    "    citi_day_count1 = citi_agg1.groupby(['bike_date', \"start_station id\"], as_index=False)['tripduration'].count()\n",
    "    citi_day_count1.columns = ['bike_date', \"start_station id\",'bike_trip_count']\n",
    "    return citi_day_count1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate by day and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns =['bike_date', 'tripduration', 'start_station id', 'start_station_latitude', 'start_station_longitude', \\\n",
    "          'end_station_id', 'end_station_latitude','end_station_longitude', 'bikeid', 'birth_year', \\\n",
    "          'gender', 'start_hour', 'end_hour','bike_trip_count', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = [\"Jan_citi\", \"Feb_citi\", \"Mar_citi\", \"Apr_citi\", \"May_citi\", \"Jun_citi\", \"Jul_citi\", \"Aug_citi\", \\\n",
    "          \"Sep_citi\", \"Oct_citi\", \"Nov_citi\", \"Dec_citi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months2 = [\"citibike_201501\", \"citibike_201502\", \"citibike_201503\", \"citibike_201504\", \"citibike_201505\", \\\n",
    "          \"citibike_201506\", \"citibike_201507\", \"citibike_201508\", \"citibike_201509\", \"citibike_201510\", \\\n",
    "          \"citibike_201511\", \"citibike_201512\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Empty dataframe\n",
    "citi_df_all_day = pd.read_csv(io.StringIO(None), names=columns, dtype=dict(zip(columns,[object, float, float, float, float, float, float, float, float, float, float, float, float, int, int])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopherstreich/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Create the files in bulk\n",
    "# By day with count and mean\n",
    "for i in (months2):\n",
    "    x = citi_agg_stat_day(str(i))\n",
    "    citi_df_all_day = citi_df_all_day.append(x, ignore_index = True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "citi_df_all_day.to_csv('data/citi_df_all_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_date</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start_station id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>bike_trip_count</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bike_date, tripduration, start_station id, start_station_latitude, start_station_longitude, end_station_id, end_station_latitude, end_station_longitude, bikeid, birth_year, gender, start_hour, end_hour, bike_trip_count, weekday]\n",
       "Index: []"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citi_df_all_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by station and time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months = [\"Jan_citi\", \"Feb_citi\", \"Mar_citi\", \"Apr_citi\", \"May_citi\", \"Jun_citi\", \"Jul_citi\", \"Aug_citi\", \\\n",
    "          \"Sep_citi\", \"Oct_citi\", \"Nov_citi\", \"Dec_citi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns2 =['bike_date', 'start_station id', 'bike_trip_count', 'birth_year', \\\n",
    "          'gender', 'start_hour', 'end_hour', 'weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station = pd.read_csv(io.StringIO(None), names=columns2, dtype=dict(zip(columns,[object, int, int])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get Station count grouped by day\n",
    "for i in (months):\n",
    "    y = citi_daystation_count(str(i))\n",
    "    citi_day_by_station = citi_day_by_station.append(y, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station.to_csv('data/citi_day_by_station.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add holiday / day of week / weekend features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays('2012', '2016', return_name=True)\n",
    "holidays.name = 'name'\n",
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays_all = pd.concat([holidays,\n",
    "                         \"Day Before \" + holidays.shift(-1, 'D'),\n",
    "                         \"Day After \" + holidays.shift(1, 'D')])\n",
    "holidays_all = holidays_all.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add holiday dummy variable\n",
    "citi_day_by_station['holiday'] = 0\n",
    "citi_day_by_station['holiday'][citi_day_by_station['bike_date'].isin(holidays_all.index.date)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station['day_of_week'] = citi_day_by_station.taxi_date.apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#control for Friday / Saturday nights\n",
    "citi_day_by_station['weekend'] = 0\n",
    "citi_day_by_station['weekend'][(citi_day_by_station['day_of_week'] == 4) | (citi_day_by_station['day_of_week'] == 5)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_features = ['bike_trip_count', 'holiday', 'weekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = citi_day_by_station[cluster_features]\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize columns\n",
    "for i in X.columns:\n",
    "    X[i] = (X[i] - X[i].mean()) / X[i].std()\n",
    "    \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n",
    "for n_clusters in range_n_clusters:\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=324)\n",
    "    cluster_labels = km.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters ={},\".format(n_clusters)+\" the average silhouette_score is :{}\".format(silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "KM=KMeans(n_clusters=n,random_state=999)\n",
    "scor=KM.fit_predict(X)\n",
    "\n",
    "res=pd.DataFrame(KM.transform(X))\n",
    "res=pd.concat((res,pd.DataFrame(KM.fit_predict(X))),axis=1)\n",
    "res.columns=list(range(n))+[\"cluster\"]\n",
    "res.loc[:,\"score\"]=res.apply(lambda x: x[int(x[\"cluster\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station['cluster'] = res.cluster\n",
    "citi_day_by_station['km_score'] = res.score\n",
    "citi_day_by_station['outlier'] = 0\n",
    "citi_day_by_station.sort_values(\"km_score\",ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bike_date</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>start_station id</th>\n",
       "      <th>start_station_latitude</th>\n",
       "      <th>start_station_longitude</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_latitude</th>\n",
       "      <th>end_station_longitude</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>bike_trip_count</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bike_date, tripduration, start_station id, start_station_latitude, start_station_longitude, end_station_id, end_station_latitude, end_station_longitude, bikeid, birth_year, gender, start_hour, end_hour, bike_trip_count, weekday]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citi_day_by_station.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station['outlier'][:10] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_color(Data1):\n",
    "    if (Data1.outlier == 1):\n",
    "        return \"red\"\n",
    "    elif (Data1.cluster == 0):\n",
    "        return \"blue\"\n",
    "    elif (Data1.cluster == 1):\n",
    "        return \"cyan\"\n",
    "    else:\n",
    "        return \"green\"\n",
    "\n",
    "citi_day_by_station = citi_day_by_station.assign(color=citi_day_by_station.apply(set_color, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(X.taxi_trip_count, X.total_amount, X.weekend, c=citi_day_by_station.color)\n",
    "ax.set_xlabel('Taxi Trip Count')\n",
    "ax.set_ylabel('average total amount $')\n",
    "ax.set_zlabel('weekend y / n')\n",
    "# set x ticks and labels\n",
    "ax.set_xticks(range(-5, 5, 1))\n",
    "# change fontsize\n",
    "for t in ax.zaxis.get_major_ticks(): t.label.set_fontsize(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(X, random_state=999, test_size=0.3)\n",
    "# fit the model\n",
    "clf = IsolationForest(max_samples=100, random_state=999)\n",
    "clf.fit(train)\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station['decision_function'] = clf.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_day_by_station.sort_values(by='decision_function').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at specific areas and see what times / dates around there are anomalies\n",
    "### Madison Square Gardens (40.750556, -73.993611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latlon_list = [40.750556, -73.993611]\n",
    "#only keep trips within a reasonable pickup lat / lon (without converting geometries)\n",
    "citi_df_total_subset = citi_day_by_station[(citi_day_by_station.start_station_latitude > (latlon_list[0] - 0.005)) & (citi_day_by_station.start_station_latitude < (latlon_list[0] + 0.005))]\n",
    "citi_df_total_subset = citi_df_total_subset[(citi_df_total_subset.start_station_longitude > (latlon_list[1] - 0.005)) & (citi_df_total_subset.start_station_longitude < (latlon_list[1] + 0.005))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to geopandas df\n",
    "geometry = [Point(xy) for xy in zip(citi_df_total_subset.start_station_longitude, citi_df_total_subset.start_station_latitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crs = {'init': 'epsg:4326'}\n",
    "citi_df_total_subset = GeoDataFrame(citi_df_total_subset, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create MSG buffer \n",
    "d = {'latitude': latlon_list[0], 'longitude': latlon_list[1]}\n",
    "MSG = pd.DataFrame(data=d, index=[0])\n",
    "geometry_MSG = [Point(xy) for xy in zip(MSG.longitude, MSG.latitude)]\n",
    "crs = {'init': 'epsg:4326'}\n",
    "MSG_gp = GeoDataFrame(crs=crs, geometry=geometry_MSG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create buffer\n",
    "MSG_gp['geometry'] = MSG_gp.geometry.buffer(.005)\n",
    "MSG_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only keep points within MSG buffer\n",
    "citi_df_total_subset = citi_df_total_subset[citi_df_total_subset.geometry.intersects(MSG_gp.geometry[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_df_total_subset['hour'] = citi_df_total_subset.tpep_pickup_datetime.apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subset to 3pm - midnight hours (to only capture relevant hours)\n",
    "#tlc_df_total_gp_subset = tlc_df_total_gp_subset[(tlc_df_total_gp_subset.hour >= 15) & (tlc_df_total_gp_subset.hour <= 23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take the mean of the taxi stats each day / hour\n",
    "citi_df_MSG_mean = citi_df_total_subset.groupby(['taxi_date'], as_index=False).mean()\n",
    "citi_df_MSG_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_df_MSG_mean['day_of_week'] = citi_df_MSG_mean.taxi_date.apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#control for Friday / Saturday nights\n",
    "citi_df_MSG_mean['weekend'] = 0\n",
    "citi_df_MSG_mean['weekend'][(citi_df_MSG_mean['day_of_week'] == 4) | (citi_df_MSG_mean['day_of_week'] == 5)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add holiday dummy variable\n",
    "citi_df_MSG_mean['holiday'] = 0\n",
    "citi_df_MSG_mean['holiday'][citi_df_MSG_mean['taxi_date'].isin(holidays_all.index.date)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in NYC street shapefile\n",
    "'''\n",
    "shapefile taken from https://geo.nyu.edu/catalog/nyu_2451_34565\n",
    "\n",
    "'''\n",
    "ny_streets_raw = gp.read_file(proj_folder + '/data/nyu_2451_34565/nyu_2451_34565.shp')\n",
    "ny_streets_raw = ny_streets_raw.to_crs(epsg=4326)\n",
    "# only keep points within MSG buffer\n",
    "ny_streets = ny_streets_raw[ny_streets_raw.geometry.intersects(MSG_gp.geometry[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# is there a way to easily plot each color differently? I have this color column highlighting outliers!\n",
    "\n",
    "MSG_sample = citi_df_MSG_mean.sample(n=1000)\n",
    "#MSG_sample.lon = MSG_sample.geometry.x\n",
    "#MSG_sample.lat = MSG_sample.geometry.y\n",
    "f, (ax1) = plt.subplots(figsize=(12,8))\n",
    "MSG_sample.plot(alpha=0.5, ax=ax1, color = 'red')\n",
    "ny_streets['geometry'].plot(alpha=1, linewidth=0.25, ax=ax1, color = '0')\n",
    "ax1.set_title(\"Plot of Taxi Pickups, Around MSG\", fontsize=20)\n",
    "plt.xlabel(\"longitude\")\n",
    "plt.ylabel(\"latitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSG anomaly analysis (isolation forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tlc_df_total_gp_subset[cluster_features]\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize columns\n",
    "for i in X.columns:\n",
    "    X[i] = (X[i] - X[i].mean()) / X[i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test=train_test_split(X, random_state=999, test_size=0.3)\n",
    "# fit the model\n",
    "clf = IsolationForest(max_samples=100, random_state=999)\n",
    "clf.fit(train)\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_df_total_subset['decision_function'] = clf.decision_function(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_df_total_subset.sort_values(by='decision_function').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Cluster Model Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n",
    "for n_clusters in range_n_clusters:\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=324)\n",
    "    cluster_labels = km.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters ={},\".format(n_clusters)+\" the average silhouette_score is :{}\".format(silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "KM=KMeans(n_clusters=n,random_state=999)\n",
    "scor=KM.fit_predict(X)\n",
    "\n",
    "res=pd.DataFrame(KM.transform(X))\n",
    "res=pd.concat((res,pd.DataFrame(KM.fit_predict(X))),axis=1)\n",
    "res.columns=list(range(n))+[\"cluster\"]\n",
    "res.loc[:,\"score\"]=res.apply(lambda x: x[int(x[\"cluster\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_df_total_subset['cluster'] = res.cluster\n",
    "citi_df_total_subset['km_score'] = res.score\n",
    "citi_df_total_subset['outlier'] = 0\n",
    "citi_df_total_subset.sort_values(\"km_score\",ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citi_df_total_subset['outlier'][:10] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_color(Data1):\n",
    "    if (Data1.outlier == 1):\n",
    "        return \"red\"\n",
    "    elif (Data1.cluster == 0):\n",
    "        return \"blue\"\n",
    "    elif (Data1.cluster == 1):\n",
    "        return \"cyan\"\n",
    "    else:\n",
    "        return \"green\"\n",
    "\n",
    "citi_df_total_subset = citi_df_total_subset.assign(color=citi_df_total_subset.apply(set_color, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(X.taxi_trip_count, X.total_amount, X.weekend, c=citi_df_total_subset.color)\n",
    "ax.set_xlabel('Taxi Trip Count')\n",
    "ax.set_ylabel('average total amount $')\n",
    "ax.set_zlabel('weekend y / n')\n",
    "# set x ticks and labels\n",
    "ax.set_xticks(range(-5, 5, 1))\n",
    "# change fontsize\n",
    "for t in ax.zaxis.get_major_ticks(): t.label.set_fontsize(10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
